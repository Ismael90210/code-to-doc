Model Setup: Ollama 
To run the project, install Ollama via https://ollama.com/ 
Run Ollama and follow instructions

Now open command prompt:
1. ollama list (check if you have any models downloaded)
2. ollama pull {model_name}:{parameter size} (downloads the model)
3. ollama run {model_name}:{parameter size}

Models used for this project:
- qwen2.5-coder
- llama3.2
- deepseek-r1
Parameter sizes:
- qwen2.5-coder
  - 0.5b
- llama3.2/3.1
  - 1b
- deepseek-r1
  - 1.5b
Direct links to the datasets 
  - https://github.com/TheAlgorithms/Python/blob/master/maths/fibonacci.py

https://github.com/TheAlgorithms/Python/blob/master/searches/binary_search.py

https://github.com/TheAlgorithms/Python/blob/master/sorts/quick_sort.py

https://github.com/psf/requests/blob/main/src/requests/api.py

https://github.com/psf/requests/blob/main/src/requests/sessions.py

https://github.com/pallets/flask/blob/main/src/flask/app.py

https://github.com/pallets/flask/blob/main/src/flask/templating.py

https://github.com/fastapi/fastapi/blob/master/fastapi/applications.py

https://github.com/fastapi/fastapi/blob/master/fastapi/routing.py

https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/metrics/_classification.py

https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/utils/_mask.py
https://github.com/microsoft/CodeXGLUE/blob/main/Code-Text/code-to-text/code/model.py
